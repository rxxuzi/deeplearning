# RNN (Recurrent Neural Networks)

RNNは、系列データや時系列データの学習に特に適しているニューラルネットワークの一種である。時系列データの特徴や前の時点の情報を保持する能力を持っており、これによって、音声認識、機械翻訳、テキスト生成などのタスクで高い性能を発揮する。

## 1. 基本的な構造

RNNの特徴的な点は、ネットワークに「記憶」を持たせることができる構造を持っていることだ。これは、時刻 $t$ での入力 $x_t$ だけでなく、前の時点 $t-1$ の隠れ層の状態 $h_{t-1}$ も入力として受け取ることで実現されている。

数式で表すと、隠れ層の状態は次のように更新される:

$$
h_t = \sigma(W_x x_t + W_h h_{t-1} + b)
$$

ここで、$W_x$ と $W_h$ は重み行列、$b$ はバイアスベクトル、$\sigma$ は活性化関数（例えばtanhやReLU）である。

## 2. 長期依存の問題

伝統的なRNNは、時系列データの中の長期的な依存関係を学習するのが難しいという問題がある。これは、勾配の消失や勾配の爆発という現象に起因する。長い系列を通過するときに、勾配が非常に小さくなったり、非常に大きくなったりすることで、モデルの学習が難しくなる。

## 3. LSTMとGRU

この長期依存の問題を解決するために、LSTM (Long Short-Term Memory) や GRU (Gated Recurrent Unit) というRNNの派生形が提案された。これらは「ゲート」という概念を導入することで、情報の流れを調節し、長期的な依存関係も効果的に学習できるようになっている。

## 4. 用途

RNNとその派生形は、以下のようなタスクで成功を収めている:

- 自然言語処理 (例: 文章生成, 機械翻訳)
- 音声認識
- 時系列予測
- 動画分析

## 5. まとめ

RNNは時系列データを扱う際の強力なツールである。その基本的な構造はシンプルであるが、深い理解と工夫を要する。特に、長期的な依存関係の学習に関する問題は、多くの研究がなされてきた分野であり、その結果としてLSTMやGRUといった高度なモデルが生まれている。