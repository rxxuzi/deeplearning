# ニューラルネットワークの基本構造

ニューラルネットワークは、様々なタスクにおいて高い性能を持つモデルの一つとして知られている。その基本構造についてまとめている

## 1. ユニット (Units)

**ユニット** または **ニューロン** (Neurons) は、ニューラルネットワークの基本的な要素であり、入力情報を受け取って出力情報を生成する役割を持つ。各ユニットは以下の式で表される。
$$
y = f(\mathbf{w} \cdot \mathbf{x} + b)
$$
ここで、$\mathbf{x}$ は入力ベクトル、$\mathbf{w}$ は重みベクトル、$b$ はバイアス、そして $f$ は活性化関数を表す。

## 2. 活性化関数 (Activation Functions)

**活性化関数(Activation Functions)** は、ニューラルネットワークのユニットからの出力を変換する非線形関数として機能する。これらの関数はネットワークの学習プロセスと複雑な問題の解決において重要な役割を担っている。代表的な活性化関数にはシグモイド関数、ReLU（Rectified Linear Unit）、タンジェントハイパーボリック（tanh）などがある。これらの関数はそれぞれ独自の特性を有し、ニューラルネットワークの異なる層で特定の目的に応じて用いられる。


- **シグモイド関数 (Sigmoid)**:
$$
f(x) = \frac{1}{1 + \exp(-x)}
$$
- **ReLU (Rectified Linear Unit)**:
$$
f(x) = \max(0, x)
$$

## 3. 順伝播型ネットワーク (Feedforward Networks)

**順伝播型ネットワーク** は、入力層から出力層までの一方向の情報の流れを持つ基本的なニューラルネットワークの形式。隠れ層を持つことができる。

## 4. 問題の定式化 (Problem Formulation)

ニューラルネットワークを効果的に学習させるためには、特定のタスクに適した方法で問題を定式化することが重要である。

例えば、画像の分類タスクでは、入力として画像データを、出力としてはカテゴリーの確率分布を用いる。数値の回帰問題では、入力データから特定の数値を予測する。このように、問題の種類に応じて適切な入力と出力の形式を設定することが不可欠である。


## 5. 尤度 (Likelihood)

**尤度(Likelihood)** は、ニューラルネットワークが生成するデータの確率を表す指標である。学習の過程では、この尤度を最大化するようにモデルのパラメータを調整する。例えば、分類問題における尤度は以下の式で計算される:

$$
L(\theta) = \prod_{i=1}^{N} P(y_i | x_i; \theta)
$$

ここで、$L(\theta)$ はパラメータ $\theta$ に対する尤度、$P(y_i | x_i; \theta)$ は入力 $x_i$ に対する正解ラベル $y_i$ の確率、$N$ はデータポイントの数を表す。目標は、この尤度を最大化するパラメータ $\theta$ を見つけることである。


## 6. 回帰と分類 (Regression and Classification)

- **回帰 (Regression)**: このタスクでは、モデルは連続値（continuous values）の出力を予測する。例えば、住宅価格の予測や気温の予測などが回帰の典型的な例である。
- **分類 (Classification)**: 分類タスクでは、モデルはカテゴリ値（categorical values）の出力を予測する。これは、例えば画像内の物体を識別する（犬、猫などのカテゴリー）や、メールがスパムか否かを判断する場合に用いられる。

## 7. 陰的表現 (Implicit Representation)

ニューラルネットワークは、与えられた学習データに基づいて複雑な関数を近似する能力を持つ。これにより、モデルはデータに含まれる隠れた特徴や構造を捉えることができる。例えば、顔認識システムは、顔の特徴的なパターンを学習し、それを基に新しい画像内の顔を識別する。

## 8. SDF (Signed Distance Function)

**SDF** または **符号付き距離関数** は、点と物体の境界までの距離とその点が物体の内部か外部かを示す符号を組み合わせて表現する関数。
