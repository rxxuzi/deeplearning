# Dropout


## 過学習（Overfitting）
- 過学習は、機械学習モデルが訓練データに対して過度に最適化し、新しい未知のデータ（テストデータや実際の運用データ）に対する予測性能が低下する現象を指す。
- モデルは訓練データのノイズや特異なパターンまで学習してしまい、一般化性能が低下する。
- 特に深層のニューラルネットワークや大量のパラメータを持つモデルでは過学習が問題となりやすい。

## Dropout
- Dropoutは、ニューラルネットワークの訓練中にランダムに一部のノード（ニューロン）を「ドロップアウト」し、そのノードを無効にするテクニック。正規化の1つに分類される
- この方法で、特定のノードやパスに過度に依存することを防ぎ、モデルがより堅牢になることが期待される。
- 訓練時にのみノードをランダムに無効にし、評価やテスト時には全ノードを使用するが、Dropoutの確率に応じてノードの出力をスケーリングするのが一般的。
- Dropoutは、過学習を防ぐための正則化手法として広く用いられる。

### 過学習が起こる主な原因としては

1. 訓練データが少ない事
2. モデルの表現力が高すぎる事

が挙げられる。

(1)の原因に関してはデータを人工的に増やす **データ拡張(data augmentation)** を利用する事が有効

(2)の原因には、 **重み減衰** や **バッチ正規化** などが有効である。
